{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0- Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import subprocess\n",
    "\n",
    "\n",
    "import exmol\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "from sklearn.svm import SVC\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "import utils\n",
    "import plots\n",
    "#import retrieve_data\n",
    "from pipeline import run_model_pipeline\n",
    "from conformal_prediction import (\n",
    "    ecfp_generator,\n",
    "    probability_dataframe,\n",
    "    run_data,\n",
    "    calculate_conformity_scores,\n",
    "    evaluate_conformal_predictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Downloading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data for three UniProt from ChEMBL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uniprot_id in [\"O43570\", \"Q16790\", \"P00918\"]:\n",
    "    retrieve_data.download_data(uniprot_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canonicalize SMILES of each ligand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [\n",
    "    \"../Data/O43570_ChEMBL_data.csv\",\n",
    "    \"../Data/P00918_ChEMBL_data.csv\",\n",
    "    \"../Data/Q16790_ChEMBL_data.csv\",\n",
    "]\n",
    "\n",
    "\n",
    "def process_smiles(row):\n",
    "    standardize_smiles = utils.canonical_smiles(row[smiles_column])\n",
    "    row[\"standardize_smiles\"] = standardize_smiles\n",
    "    return row\n",
    "\n",
    "\n",
    "# Loop through each CSV file\n",
    "for csv_file in csv_files:\n",
    "    print(f\"{csv_file} UniProt...\")\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    smiles_column = \"smiles\"\n",
    "\n",
    "    data = data.apply(process_smiles, axis=1)\n",
    "\n",
    "    # Save the updated DataFrame to a new file\n",
    "    output_file = csv_file.replace(\".csv\", \"_canonical_smiles.csv\")\n",
    "    data.to_csv(output_file, index=False)\n",
    "    print(f\"Processed '{csv_file}' and saved to '{output_file}'\")\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Substructure Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter data based on sulfonamide functional group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [\n",
    "    \"../Data/O43570_ChEMBL_data_canonical_smiles.csv\",\n",
    "    \"../Data/P00918_ChEMBL_data_canonical_smiles.csv\",\n",
    "    \"../Data/Q16790_ChEMBL_data_canonical_smiles.csv\",\n",
    "]\n",
    "\n",
    "# Loop through eeach CSV file\n",
    "for csv_file in csv_files:\n",
    "    print(f\"{csv_file} UniProt...\")\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Extract SMILES strings from the specified column\n",
    "    smiles_column = df.loc[:, \"smiles\"]\n",
    "\n",
    "    # Check for sulfonamide substructure\n",
    "    has_sulfonamide = smiles_column.apply(utils.check_sulfonamide)\n",
    "\n",
    "    # Add a new column indicating the presence of sulfonamide\n",
    "    df.loc[:, \"has_sulfonamide\"] = has_sulfonamide\n",
    "\n",
    "    # Save the updated DataFrame to a new file\n",
    "    output_file = csv_file.replace(\".csv\", \"_filtered.csv\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(\n",
    "        f\"From {df.shape[0]} data points {has_sulfonamide.sum()} has primary sulfonamide.\"\n",
    "    )\n",
    "    print(f\"Processed '{csv_file}' and saved to '{output_file}'\")\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate statistics of binding affinity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    \"../Data/P00918_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/Q16790_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/O43570_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "]\n",
    "\n",
    "\n",
    "all_stats = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    stats = utils.calculate_statistics(df[\"pK\"])\n",
    "\n",
    "    all_stats.append(stats)\n",
    "\n",
    "\n",
    "combined_stats = pd.DataFrame(all_stats).transpose().round(3)\n",
    "\n",
    "file_names = [\"II\", \"IX\", \"XII\"]\n",
    "\n",
    "combined_stats.columns = file_names\n",
    "\n",
    "combined_stats.to_csv(\"../Data/binding_affinity_statistics.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Count Binding Affinity Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of different Ki, Kd, and IC50 for a compiled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    \"../Data/O43570_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/P00918_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/Q16790_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "]\n",
    "\n",
    "types = [\"IC50\", \"Ki\", \"Kd\"]\n",
    "\n",
    "counts_dict = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "    name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    df = pd.read_csv(file_path)\n",
    "    counts = utils.count_letters(df, types)\n",
    "    counts_dict[name] = counts\n",
    "\n",
    "pd.DataFrame(counts_dict).transpose().to_csv(\n",
    "    \"../Data/binding_affinity_types_counts.csv\", index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6- Calculate Molecular Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate several molecular properties and return their statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    \"../Data/P00918_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/Q16790_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/O43570_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "]\n",
    "\n",
    "\n",
    "for file_path in file_paths:\n",
    "\n",
    "    utils.calculate_molecular_property(file_path)\n",
    "\n",
    "\n",
    "file_paths = [\n",
    "    \"../Data/P00918_molecular_property.csv\",\n",
    "    \"../Data/Q16790_molecular_property.csv\",\n",
    "    \"../Data/O43570_molecular_property.csv\",\n",
    "]\n",
    "\n",
    "\n",
    "for file_path in file_paths:\n",
    "\n",
    "    utils.molecular_property_stats(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7- Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-1- pKa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot KDE diagram of pKa values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_manager.findfont(\"Helvetica\")\n",
    "plt.rc(\"font\", family=\"Helvetica\")\n",
    "plt.rc(\"font\", serif=\"Helvetica\", size=32)\n",
    "plt.rcParams[\"axes.linewidth\"] = 1.25\n",
    "plt.rcParams[\"xtick.major.size\"] = 10\n",
    "plt.rcParams[\"xtick.minor.size\"] = 2\n",
    "plt.rcParams[\"xtick.major.width\"] = 1.5\n",
    "plt.rcParams[\"xtick.minor.width\"] = 1.5\n",
    "plt.rcParams[\"ytick.major.size\"] = 10\n",
    "plt.rcParams[\"ytick.minor.size\"] = 2\n",
    "plt.rcParams[\"ytick.major.width\"] = 1.5\n",
    "plt.rcParams[\"ytick.minor.width\"] = 1.5\n",
    "plt.rcParams[\"ytick.direction\"] = \"in\"\n",
    "plt.rcParams[\"xtick.direction\"] = \"in\"\n",
    "\n",
    "plt.rcParams[\"mathtext.it\"] = \"Helvetica :italic\"\n",
    "plt.rcParams[\"mathtext.rm\"] = \"Helvetica\"\n",
    "plt.rcParams[\"mathtext.default\"] = \"regular\"\n",
    "\n",
    "file_paths = [\n",
    "    \"../Data/P00918_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/Q16790_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/O43570_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "]\n",
    "\n",
    "\n",
    "colors = [\"#bee9e8\", \"#62b6cb\", \"#1b4965\"]\n",
    "\n",
    "plots.plot_pka(file_paths, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-2- Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot molecular properties KDE diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_manager.findfont(\"Helvetica Light\")\n",
    "plt.rc(\"font\", family=\"Helvetica Light\")\n",
    "plt.rc(\"font\", serif=\"Helvetica Light\", size=25)\n",
    "plt.rcParams[\"axes.linewidth\"] = 1.25\n",
    "plt.rcParams[\"xtick.major.size\"] = 8\n",
    "plt.rcParams[\"xtick.minor.size\"] = 2\n",
    "plt.rcParams[\"xtick.major.width\"] = 1.25\n",
    "plt.rcParams[\"xtick.minor.width\"] = 1.25\n",
    "plt.rcParams[\"ytick.major.size\"] = 8\n",
    "plt.rcParams[\"ytick.minor.size\"] = 2\n",
    "plt.rcParams[\"ytick.major.width\"] = 1.25\n",
    "plt.rcParams[\"ytick.minor.width\"] = 1.25\n",
    "plt.rcParams[\"ytick.direction\"] = \"in\"\n",
    "plt.rcParams[\"xtick.direction\"] = \"in\"\n",
    "\n",
    "plt.rcParams[\"mathtext.it\"] = \"Helvetica Light:italic\"\n",
    "plt.rcParams[\"mathtext.rm\"] = \"Helvetica Light\"\n",
    "plt.rcParams[\"mathtext.default\"] = \"regular\"\n",
    "\n",
    "\n",
    "file_paths = [\n",
    "    \"../Data/P00918_molecular_property.csv\",\n",
    "    \"../Data/Q16790_molecular_property.csv\",\n",
    "    \"../Data/O43570_molecular_property.csv\",\n",
    "]\n",
    "\n",
    "colors = [\"#bee9e8\", \"#62b6cb\", \"#1b4965\"]\n",
    "\n",
    "plots.plot_property(file_paths, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-3- T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot T-SNE diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_manager.findfont(\"Helvetica Light\")\n",
    "plt.rc(\"font\", family=\"Helvetica Light\")\n",
    "plt.rc(\"font\", serif=\"Helvetica Light\", size=20)\n",
    "plt.rcParams[\"axes.linewidth\"] = 1.25\n",
    "plt.rcParams[\"xtick.major.size\"] = 8\n",
    "plt.rcParams[\"xtick.minor.size\"] = 2\n",
    "plt.rcParams[\"xtick.major.width\"] = 1.25\n",
    "plt.rcParams[\"xtick.minor.width\"] = 1.25\n",
    "plt.rcParams[\"ytick.major.size\"] = 8\n",
    "plt.rcParams[\"ytick.minor.size\"] = 2\n",
    "plt.rcParams[\"ytick.major.width\"] = 1.25\n",
    "plt.rcParams[\"ytick.minor.width\"] = 1.25\n",
    "plt.rcParams[\"ytick.direction\"] = \"in\"\n",
    "plt.rcParams[\"xtick.direction\"] = \"in\"\n",
    "\n",
    "plt.rcParams[\"mathtext.it\"] = \"Helvetica Light:italic\"\n",
    "plt.rcParams[\"mathtext.rm\"] = \"Helvetica Light\"\n",
    "plt.rcParams[\"mathtext.default\"] = \"regular\"\n",
    "\n",
    "file_paths = [\n",
    "    \"../Data/P00918_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/Q16790_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/O43570_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "]\n",
    "\n",
    "colors = [\"#f46036\", \"#2e294e\", \"#1b998b\"]\n",
    "\n",
    "\n",
    "plot_t_sne(file_paths, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8- Train-Test-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-1- LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8-1-1- Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_pipeline(model_type=\"logistic\", split_type=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8-1-2- Scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_pipeline(model_type=\"logistic\", split_type=\"scaffold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"rb\") as f:\n",
    "    data_split = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-2- SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-2-1- Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_pipeline(model_type=\"svm\", split_type=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-2-2- Scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_pipeline(model_type=\"svm\", split_type=\"scaffold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-3- RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-3-1- Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_pipeline(model_type=\"randomforest\", split_type=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-3-2- Scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_pipeline(model_type=\"randomforest\", split_type=\"scaffold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-4- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-4-1- Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_pipeline(model_type=\"xgboost\", split_type=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-4-2- Scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_pipeline(model_type=\"xgboost\", split_type=\"scaffold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-5- FFNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-5-1- Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_pipeline(model_type=\"ffneuralnetwork\", split_type=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-5-2- Scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_pipeline(model_type=\"ffneuralnetwork\", split_type=\"scaffold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-6- GIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-6-1- Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_pipeline(model_type=\"gin\", split_type=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-6-2- Scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_pipeline(model_type=\"gin\", split_type=\"scaffold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9- Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-1- McNemar Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run([\"python\", \"mcnemar_test.py\"], capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10- Conformal Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-1- Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_to_isoform = {\"P00918\": \"CA2\", \"Q16790\": \"CA9\", \"O43570\": \"CA12\"}\n",
    "\n",
    "CA2_HP = {\n",
    "    \"C\": 66.96581256335178,\n",
    "    \"kernel\": \"rbf\",\n",
    "    \"gamma\": \"scale\",\n",
    "    \"coef0\": 0.4168195903861248,\n",
    "}\n",
    "CA9_HP = {\n",
    "    \"C\": 268.35706901387067,\n",
    "    \"kernel\": \"poly\",\n",
    "    \"gamma\": \"scale\",\n",
    "    \"coef0\": 0.7717853353913062,\n",
    "}\n",
    "CA12_HP = {\n",
    "    \"C\": 2.320983366278537,\n",
    "    \"kernel\": \"rbf\",\n",
    "    \"gamma\": \"scale\",\n",
    "    \"coef0\": 0.9704194409850162,\n",
    "}\n",
    "\n",
    "file_paths = [\n",
    "    \"../Data/O43570_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/P00918_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/Q16790_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "]\n",
    "\n",
    "folds_dict = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "\n",
    "    name = file_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    x = df.loc[:, \"standardize_smiles\"].to_numpy()\n",
    "    y = df.loc[:, \"status\"].values\n",
    "\n",
    "    dataset = dc.data.DiskDataset.from_numpy(X=x, y=y, w=np.zeros(len(x)), ids=x)\n",
    "    for i in range(10):\n",
    "        scaffoldsplitter = dc.splits.ScaffoldSplitter()\n",
    "        train_set, val_set, test_set = scaffoldsplitter.train_valid_test_split(\n",
    "            dataset, frac_train=0.7, frac_valid=0.1, frac_test=0.2\n",
    "        )\n",
    "\n",
    "        X_train, y_train = train_set.X, train_set.y.reshape(-1)\n",
    "        X_val, y_val = val_set.X, val_set.y.reshape(-1)\n",
    "        X_test, y_test = test_set.X, test_set.y.reshape(-1)\n",
    "\n",
    "        ecfp_fv_dict = {}\n",
    "\n",
    "        X_train_ecfp = ecfp_generator(X_train)\n",
    "        X_val_ecfp = ecfp_generator(X_val)\n",
    "        X_test_ecfp = ecfp_generator(X_test)\n",
    "\n",
    "        ros = RandomOverSampler()\n",
    "        X_train_ecfp_resampled, y_train_resampled = ros.fit_resample(\n",
    "            X_train_ecfp, y_train\n",
    "        )\n",
    "\n",
    "        ecfp_fv_dict = {\n",
    "            \"train_fv\": X_train_ecfp_resampled,\n",
    "            \"train_label\": y_train_resampled,\n",
    "            \"val_fv\": X_val_ecfp,\n",
    "            \"val_label\": y_val,\n",
    "            \"test_fv\": X_test_ecfp,\n",
    "            \"test_label\": y_test,\n",
    "        }\n",
    "\n",
    "        folds_dict[f\"{name}_split_{i}\"] = ecfp_fv_dict\n",
    "\n",
    "for name in [\"P00918\", \"Q16790\", \"O43570\"]:\n",
    "    if name == \"P00918\":\n",
    "        models = [SVC(**CA2_HP, probability=True) for _ in range(10)]\n",
    "\n",
    "    elif name == \"Q16790\":\n",
    "        models = [SVC(**CA9_HP, probability=True) for _ in range(10)]\n",
    "    else:\n",
    "        models = [SVC(**CA12_HP, probability=True) for _ in range(10)]\n",
    "\n",
    "    models = [\n",
    "        svm.fit(\n",
    "            folds_dict[f\"{name}_split_{i}\"][\"train_fv\"],\n",
    "            folds_dict[f\"{name}_split_{i}\"][\"train_label\"],\n",
    "        )\n",
    "        for i, svm in enumerate(models)\n",
    "    ]\n",
    "\n",
    "    probability_dataframe(models, folds_dict, name, split_type=\"val\")\n",
    "    probability_dataframe(models, folds_dict, name, split_type=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-2- Evaluation (Validity and Efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for isoform in [\"CA2\", \"CA9\", \"CA12\"]:\n",
    "    cal_file = f\"../Results/Conformal_Prediction/svm_ecfp_{isoform}_val_prob.csv\"\n",
    "    test_file = f\"../Results/Conformal_Prediction/svm_ecfp_{isoform}_test_prob.csv\"\n",
    "\n",
    "    cal_df = pd.read_csv(cal_file)\n",
    "    test_df = pd.read_csv(test_file)\n",
    "\n",
    "    epsilons = [0.01, 0.05, 0.1, 0.15, 0.20, 0.25, 0.3]\n",
    "    num_runs = 10\n",
    "\n",
    "    avg_validities = []\n",
    "    avg_efficiencies_tl = []\n",
    "    avg_empty_rate_overalls = []\n",
    "\n",
    "    for epsilon in epsilons:\n",
    "        run_validities = []\n",
    "        run_efficiencies_tl = []\n",
    "        run_empty_rates = []\n",
    "\n",
    "        for i in range(num_runs):\n",
    "\n",
    "            p_active_cal, p_inactive_cal, labels_cal = run_data(cal_df, i)\n",
    "            p_active_test, p_inactive_test, labels_test = run_data(test_df, i)\n",
    "\n",
    "            calibration_scores_dict = calculate_conformity_scores(\n",
    "                p_active_cal, p_inactive_cal, labels_cal\n",
    "            )\n",
    "\n",
    "            validity, efficiency_tl, empty_rate = evaluate_conformal_predictor(\n",
    "                p_active_test,\n",
    "                p_inactive_test,\n",
    "                labels_test,\n",
    "                calibration_scores_dict,\n",
    "                epsilon,\n",
    "            )\n",
    "            run_validities.append(validity)\n",
    "            run_efficiencies_tl.append(efficiency_tl)\n",
    "            run_empty_rates.append(empty_rate)\n",
    "\n",
    "        avg_validity = np.mean(run_validities)\n",
    "        avg_efficiency_tl = np.mean(run_efficiencies_tl)\n",
    "        avg_empty_rate_overall = np.mean(run_empty_rates)\n",
    "\n",
    "        avg_validities.append(avg_validity)\n",
    "        avg_efficiencies_tl.append(avg_efficiency_tl)\n",
    "        avg_empty_rate_overalls.append(avg_empty_rate_overall)\n",
    "\n",
    "        cp_single_result_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Validity\": run_validities,\n",
    "                \"Efficiency\": run_efficiencies_tl,\n",
    "                \"Empty Rate\": run_empty_rates,\n",
    "            }\n",
    "        )\n",
    "        cp_single_result_df.to_csv(\n",
    "            f\"../Results/Conformal_Prediction/cp_{isoform}_{epsilon}.csv\", index=False\n",
    "        )\n",
    "\n",
    "    cp_total_result_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Epsilon\": epsilons,\n",
    "            \"Avg Validity\": avg_validities,\n",
    "            \"Avg Efficiency\": avg_efficiencies_tl,\n",
    "            \"Avg Empty Rate\": avg_empty_rate_overalls,\n",
    "        }\n",
    "    ).to_csv(f\"../Results/Conformal_Prediction/cp_result_{isoform}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11- XAI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11-0 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counterfactual_explain(samples, name):\n",
    "    sns.set_context(\"notebook\")\n",
    "    sns.set_style(\"dark\")\n",
    "\n",
    "    font_manager.findfont(\"Helvetica\")\n",
    "    plt.rc(\"font\", family=\"Helvetica\")\n",
    "    plt.rc(\"font\", serif=\"Helvetica\", size=22)\n",
    "    fkw = {\n",
    "        \"figsize\": (8, 6),  # Width, height in inches\n",
    "        \"dpi\": 600,  # Dots per inch (high-res)\n",
    "        \"facecolor\": \"white\",  # Background color of the figure\n",
    "        \"edgecolor\": \"white\",  # Edge color of the figure\n",
    "    }\n",
    "\n",
    "    cfs = exmol.cf_explain(samples, nmols=3)\n",
    "    exmol.plot_cf(cfs, figure_kwargs=fkw, mol_size=(350, 300), nrows=2, mol_fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{name}_counterfactual_samples.pdf\", bbox_inches=\"tight\")\n",
    "    svg = exmol.insert_svg(cfs)\n",
    "    with open(f\"{name}_counterfactual_samples.svg\", \"w\") as f:\n",
    "        f.write(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counterfactual_space(samples, name):\n",
    "    sns.set_context(\"notebook\")\n",
    "    sns.set_style(\"dark\")\n",
    "\n",
    "    font_manager.findfont(\"Helvetica\")\n",
    "    plt.rc(\"font\", family=\"Helvetica\")\n",
    "    plt.rc(\"font\", serif=\"Helvetica\", size=22)\n",
    "    fkw = {\n",
    "        \"figsize\": (10, 8),  # Width, height in inches\n",
    "        \"dpi\": 300,  # Dots per inch (high-res)\n",
    "        \"facecolor\": \"white\",  # Background color of the figure\n",
    "        \"edgecolor\": \"white\",  # Edge color of the figure\n",
    "    }\n",
    "\n",
    "    cfs = exmol.cf_explain(samples, nmols=3)\n",
    "    exmol.plot_space(\n",
    "        samples, cfs, figure_kwargs=fkw, mol_size=(350, 300), mol_fontsize=8\n",
    "    )\n",
    "    plt.scatter([], [], label=\"Same Class\", s=150, color=plt.get_cmap(\"viridis\")(1.0))\n",
    "    plt.scatter(\n",
    "        [], [], label=\"Counterfactual\", s=150, color=plt.get_cmap(\"viridis\")(0.0)\n",
    "    )\n",
    "    plt.legend(\n",
    "        fontsize=22,  # Font size of the legend text\n",
    "        loc=None,  # Location of the legend; None = automatic best placement\n",
    "        ncol=1,  # Number of columns in the legend\n",
    "        frameon=True,  # Whether to draw a border/frame around the legend\n",
    "        shadow=False,  # Whether to draw a shadow behind the legend\n",
    "        title=None,  # Title text for the legend (None = no title)\n",
    "        title_fontsize=18,  # Font size of the legend title\n",
    "        facecolor=\"white\",  # Background color of the legend box\n",
    "        edgecolor=\"black\",  # Border color of the legend box\n",
    "        framealpha=0.8,  # Transparency of the legend frame (0 = fully transparent, 1 = opaque)\n",
    "        labelspacing=0.5,  # Vertical space between legend entries (in font-size units)\n",
    "        handlelength=2.5,  # Length of the legend handles (lines or markers)\n",
    "        handletextpad=1.0,  # Padding between handle and text (in font-size units)\n",
    "        borderpad=0.5,  # Padding inside the legend border (in fraction of font size)\n",
    "        borderaxespad=0.4,  # Padding between the legend and the axes (in fraction of font size)\n",
    "        columnspacing=1.5,  # Horizontal spacing between columns (if ncol > 1)\n",
    "        fancybox=True,  # Whether to draw a rounded box (True) or square box (False)\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(\"{name}_counterfactual_space.pdf\", bbox_inches=\"tight\")\n",
    "    svg = exmol.insert_svg(cfs)\n",
    "    with open(f\"{name}_counterfactual_space.svg\", \"w\") as f:\n",
    "        f.write(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11-1- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_to_isoform = {\"P00918\": \"CA2\", \"Q16790\": \"CA9\", \"O43570\": \"CA12\"}\n",
    "\n",
    "CA2_HP = {\n",
    "    \"C\": 66.96581256335178,\n",
    "    \"kernel\": \"rbf\",\n",
    "    \"gamma\": \"scale\",\n",
    "    \"coef0\": 0.4168195903861248,\n",
    "}\n",
    "CA9_HP = {\n",
    "    \"C\": 268.35706901387067,\n",
    "    \"kernel\": \"poly\",\n",
    "    \"gamma\": \"scale\",\n",
    "    \"coef0\": 0.7717853353913062,\n",
    "}\n",
    "CA12_HP = {\n",
    "    \"C\": 2.320983366278537,\n",
    "    \"kernel\": \"rbf\",\n",
    "    \"gamma\": \"scale\",\n",
    "    \"coef0\": 0.9704194409850162,\n",
    "}\n",
    "\n",
    "file_paths = [\n",
    "    \"../Data/O43570_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/P00918_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/Q16790_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "]\n",
    "\n",
    "folds_dict = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "\n",
    "    name = file_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "\n",
    "    if os.path.exists(f\"svm_{name}.pkl\"):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    x = df.loc[:, \"standardize_smiles\"].to_numpy()\n",
    "    y = df.loc[:, \"status\"].values\n",
    "\n",
    "    dataset = dc.data.DiskDataset.from_numpy(X=x, y=y, w=np.zeros(len(x)), ids=x)\n",
    "\n",
    "    scaffoldsplitter = dc.splits.ScaffoldSplitter()\n",
    "    train_set, val_set, test_set = scaffoldsplitter.train_valid_test_split(\n",
    "        dataset, frac_train=0.7, frac_valid=0.1, frac_test=0.2, seed=42\n",
    "    )\n",
    "\n",
    "    X_train, y_train = train_set.X, train_set.y.reshape(-1)\n",
    "    X_val, y_val = val_set.X, val_set.y.reshape(-1)\n",
    "    X_test, y_test = test_set.X, test_set.y.reshape(-1)\n",
    "\n",
    "    ecfp_fv_dict = {}\n",
    "\n",
    "    X_train_ecfp = ecfp_generator(X_train)\n",
    "    X_val_ecfp = ecfp_generator(X_val)\n",
    "    X_test_ecfp = ecfp_generator(X_test)\n",
    "\n",
    "    ros = RandomOverSampler()\n",
    "    X_train_ecfp_resampled, y_train_resampled = ros.fit_resample(X_train_ecfp, y_train)\n",
    "\n",
    "    ecfp_fv_dict = {\n",
    "        \"train_fv\": X_train_ecfp_resampled,\n",
    "        \"train_label\": y_train_resampled,\n",
    "        \"val_fv\": X_val_ecfp,\n",
    "        \"val_label\": y_val,\n",
    "        \"test_fv\": X_test_ecfp,\n",
    "        \"test_label\": y_test,\n",
    "    }\n",
    "\n",
    "    folds_dict[f\"{name}_split\"] = ecfp_fv_dict\n",
    "\n",
    "for name in [\"P00918\", \"Q16790\", \"O43570\"]:\n",
    "\n",
    "    if os.path.exists(f\"svm_{name}.pkl\"):\n",
    "        continue\n",
    "    if name == \"P00918\":\n",
    "        svm = SVC(**CA2_HP, random_state=42)\n",
    "\n",
    "    elif name == \"Q16790\":\n",
    "        svm = SVC(**CA9_HP, random_state=42)\n",
    "    else:\n",
    "        svm = SVC(**CA12_HP, random_state=42)\n",
    "\n",
    "    svm.fit(\n",
    "        folds_dict[f\"{name}_split\"][\"train_fv\"],\n",
    "        folds_dict[f\"{name}_split\"][\"train_label\"],\n",
    "    )\n",
    "\n",
    "    with open(f\"svm_{name}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(svm, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11-2- Isoform II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"svm_P00918.pkl\", \"rb\") as file:\n",
    "    svm = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"NS(=O)(=O)c1ccc(NC(=O)Nc2ccc(F)cc2)cc1\"\n",
    "\n",
    "\n",
    "def model(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    ecfp_fv = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "    y_predict = svm.predict(np.array(ecfp_fv).reshape(1, -1))\n",
    "    return 1 if y_predict else 0\n",
    "\n",
    "\n",
    "samples = exmol.sample_space(base, model, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_explain(samples, \"P00918\")\n",
    "counterfactual_space(samples, \"P00918\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11-3- Isoform IX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"svm_Q16790.pkl\", \"rb\") as file:\n",
    "    svm = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"NS(=O)(=O)c1ccc(NC(=O)Nc2ccc(F)cc2)cc1\"\n",
    "\n",
    "\n",
    "def model(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    ecfp_fv = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "    y_predict = svm.predict(np.array(ecfp_fv).reshape(1, -1))\n",
    "    return 1 if y_predict else 0\n",
    "\n",
    "\n",
    "samples = exmol.sample_space(base, model, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_explain(samples, \"Q16790\")\n",
    "counterfactual_space(samples, \"Q16790\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11-4- Isoform XII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"svm_O43570.pkl\", \"rb\") as file:\n",
    "    svm = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"NS(=O)(=O)c1ccc(NC(=O)Nc2ccc(F)cc2)cc1\"\n",
    "\n",
    "\n",
    "def model(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    ecfp_fv = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "    y_predict = svm.predict(np.array(ecfp_fv).reshape(1, -1))\n",
    "    return 1 if y_predict else 0\n",
    "\n",
    "\n",
    "samples = exmol.sample_space(base, model, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_explain(samples, \"O43570\")\n",
    "counterfactual_space(samples, \"O43570\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12- GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12-1- Training and Calibration Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_to_isoform = {\"P00918\": \"CA2\", \"Q16790\": \"CA9\", \"O43570\": \"CA12\"}\n",
    "\n",
    "CA2_HP = {\n",
    "    \"C\": 66.96581256335178,\n",
    "    \"kernel\": \"rbf\",\n",
    "    \"gamma\": \"scale\",\n",
    "    \"coef0\": 0.4168195903861248,\n",
    "}\n",
    "CA9_HP = {\n",
    "    \"C\": 268.35706901387067,\n",
    "    \"kernel\": \"poly\",\n",
    "    \"gamma\": \"scale\",\n",
    "    \"coef0\": 0.7717853353913062,\n",
    "}\n",
    "CA12_HP = {\n",
    "    \"C\": 2.320983366278537,\n",
    "    \"kernel\": \"rbf\",\n",
    "    \"gamma\": \"scale\",\n",
    "    \"coef0\": 0.9704194409850162,\n",
    "}\n",
    "\n",
    "file_paths = [\n",
    "    \"../Data/O43570_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/P00918_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "    \"../Data/Q16790_ChEMBL_data_canonical_smiles_filtered_status.csv\",\n",
    "]\n",
    "\n",
    "folds_dict = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "\n",
    "    name = file_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    x = df.loc[:, \"standardize_smiles\"].to_numpy()\n",
    "    y = df.loc[:, \"status\"].values\n",
    "\n",
    "    dataset = dc.data.DiskDataset.from_numpy(X=x, y=y, w=np.zeros(len(x)), ids=x)\n",
    "\n",
    "    scaffoldsplitter = dc.splits.ScaffoldSplitter()\n",
    "    train_set, val_set, test_set = scaffoldsplitter.train_valid_test_split(\n",
    "        dataset, frac_train=0.7, frac_valid=0.1, frac_test=0.2, seed=42\n",
    "    )\n",
    "\n",
    "    X_train, y_train = train_set.X, train_set.y.reshape(-1)\n",
    "    X_val, y_val = val_set.X, val_set.y.reshape(-1)\n",
    "    X_test, y_test = test_set.X, test_set.y.reshape(-1)\n",
    "\n",
    "    ecfp_fv_dict = {}\n",
    "\n",
    "    X_train_ecfp = ecfp_generator(X_train)\n",
    "    X_val_ecfp = ecfp_generator(X_val)\n",
    "    X_test_ecfp = ecfp_generator(X_test)\n",
    "\n",
    "    ros = RandomOverSampler()\n",
    "    X_train_ecfp_resampled, y_train_resampled = ros.fit_resample(X_train_ecfp, y_train)\n",
    "\n",
    "    ecfp_fv_dict = {\n",
    "        \"train_fv\": X_train_ecfp_resampled,\n",
    "        \"train_label\": y_train_resampled,\n",
    "        \"val_fv\": X_val_ecfp,\n",
    "        \"val_label\": y_val,\n",
    "        \"test_fv\": X_test_ecfp,\n",
    "        \"test_label\": y_test,\n",
    "    }\n",
    "\n",
    "    folds_dict[f\"{name}_split\"] = ecfp_fv_dict\n",
    "\n",
    "for name in [\"P00918\", \"Q16790\", \"O43570\"]:\n",
    "\n",
    "    if os.path.exists(f\"svm_{name}.pkl\"):\n",
    "        continue\n",
    "    if name == \"P00918\":\n",
    "        svm = SVC(**CA2_HP, probability=True, random_state=42)\n",
    "\n",
    "    elif name == \"Q16790\":\n",
    "        svm = SVC(**CA9_HP, probability=True, random_state=42)\n",
    "    else:\n",
    "        svm = SVC(**CA12_HP, probability=True, random_state=42)\n",
    "\n",
    "    svm.fit(\n",
    "        folds_dict[f\"{name}_split\"][\"train_fv\"],\n",
    "        folds_dict[f\"{name}_split\"][\"train_label\"],\n",
    "    )\n",
    "\n",
    "    with open(f\"svm_{name}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(svm, file)\n",
    "\n",
    "with open('svm_P00918.pkl', 'rb') as f:\n",
    "    ca2_svm = pickle.load(f)\n",
    "\n",
    "with open('svm_Q16790.pkl', 'rb') as f:\n",
    "    ca9_svm = pickle.load(f)\n",
    "\n",
    "with open('svm_O43570.pkl', 'rb') as f:\n",
    "    ca12_svm = pickle.load(f)\n",
    "\n",
    "\n",
    "for name in [\"P00918\", \"Q16790\", \"O43570\"]:\n",
    "        split = folds_dict[f\"{name}_split\"]\n",
    "        if name == \"P00918\":\n",
    "                pred_df = pd.DataFrame(ca2_svm.predict_proba(split[f\"val_fv\"]))\n",
    "        elif name == \"Q16790\":\n",
    "                pred_df = pd.DataFrame(ca9_svm.predict_proba(split[f\"val_fv\"]))\n",
    "        else: \n",
    "                pred_df = pd.DataFrame(ca12_svm.predict_proba(split[f\"val_fv\"]))\n",
    "\n",
    "        pred_df.columns = [\"active\", \"inactive\"]\n",
    "        label_df = pd.DataFrame(split[f\"val_label\"])\n",
    "        label_df = label_df.rename({0: \"label\"}, axis=1)\n",
    "        final_df = pd.concat([pred_df, label_df], axis=1)\n",
    "        final_df.to_csv(\n",
    "                f\"svm_ecfp_{uniprot_to_isoform[name]}_prob.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12-2- Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import exmol\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import font_manager\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "\n",
    "def predict_with_conformal(\n",
    "    smiles: str, model_info: Dict[str, Tuple[str, str]], epsilon: float = 0.3\n",
    ") -> Dict[str, List[int]]:\n",
    "    \"\"\"\n",
    "    Predicts class membership for a molecule using conformal prediction with SVM models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles : str\n",
    "        Molecule in SMILES format.\n",
    "    model_info : dict of str to tuple (str, str)\n",
    "        Mapping of model labels to (model pickle file path, calibration CSV file path).\n",
    "    epsilon : float, optional\n",
    "        Threshold for class inclusion in prediction set (default is 0.3).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict of str to list of int\n",
    "        Dictionary mapping model labels to prediction sets (class indices 0 or 1).\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        raise ValueError(\"Invalid SMILES string\")\n",
    "\n",
    "    ecfp_fv = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "    feature_array = np.array(ecfp_fv).reshape(1, -1)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for label, (model_file, calibration_csv) in model_info.items():\n",
    "        with open(model_file, \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "\n",
    "        cal_scores_df = pd.read_csv(calibration_csv)\n",
    "        probs = model.predict_proba(feature_array)[0]\n",
    "        prediction_set = []\n",
    "\n",
    "        for class_idx, class_name in enumerate([\"inactive\", \"active\"]):\n",
    "            conformity_scores = cal_scores_df[class_name].to_numpy()\n",
    "            score_test = probs[class_idx]\n",
    "            p_value = (np.sum(conformity_scores <= score_test) + 1) / (\n",
    "                len(conformity_scores) + 1\n",
    "            )\n",
    "            if p_value > epsilon:\n",
    "                prediction_set.append(class_idx)\n",
    "\n",
    "        results[label] = prediction_set\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def model(smiles: str, svm) -> int:\n",
    "    \"\"\"\n",
    "    Predict the binary class of a molecule using an SVM model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles : str\n",
    "        SMILES string representing the molecule.\n",
    "    svm : object\n",
    "        Preloaded SVM model with a `predict` method.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Predicted class label (0 or 1).\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    ecfp_fv = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "    y_predict = svm.predict(np.array(ecfp_fv).reshape(1, -1))\n",
    "    return int(y_predict[0])\n",
    "\n",
    "\n",
    "def counterfactual_explain(samples, name: str):\n",
    "    \"\"\"\n",
    "    Generate and save counterfactual explanations for molecule samples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples : list\n",
    "        Molecular samples to explain, typically output from `exmol.sample_space`.\n",
    "    name : str\n",
    "        Identifier prefix for the saved SVG file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Saves an SVG file named '{name}_counterfactual_samples.svg' with counterfactual plots.\n",
    "    \"\"\"\n",
    "    sns.set_context(\"notebook\")\n",
    "    sns.set_style(\"dark\")\n",
    "\n",
    "    font_manager.findfont(\"Helvetica\")\n",
    "    plt.rc(\"font\", family=\"Helvetica\")\n",
    "    plt.rc(\"font\", serif=\"Helvetica\", size=22)\n",
    "\n",
    "    fkw = {\n",
    "        \"figsize\": (8, 6),\n",
    "        \"dpi\": 300,\n",
    "        \"facecolor\": \"white\",\n",
    "        \"edgecolor\": \"white\",\n",
    "    }\n",
    "\n",
    "    cfs = exmol.cf_explain(samples, nmols=3)\n",
    "    exmol.plot_cf(cfs, figure_kwargs=fkw, mol_size=(350, 300), nrows=2, mol_fontsize=8)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    svg = exmol.insert_svg(cfs)\n",
    "    with open(f\"{name}_counterfactual_samples.svg\", \"w\") as f:\n",
    "        f.write(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = \"NS(=O)(=O)c1ccc(NC(=O)Nc2ccc(F)cc2)cc1\"\n",
    "\n",
    "model_info = {\n",
    "    'CA2': ('svm_P00918.pkl', 'svm_ecfp_CA2_prob.csv'),\n",
    "    'CA9': ('svm_Q16790.pkl', 'svm_ecfp_CA9_prob.csv'),\n",
    "    'CA12': ('svm_O43570.pkl', 'svm_ecfp_CA12_prob.csv')\n",
    "}\n",
    "\n",
    "predictions = predict_with_conformal(smiles, model_info)\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "isoform_models = {\n",
    "    \"CA2\": \"svm_P00918.pkl\",\n",
    "    \"CA9\": \"svm_Q16790.pkl\",\n",
    "    \"CA12\": \"svm_O43570.pkl\"\n",
    "}\n",
    "\n",
    "for isoform, model_path in isoform_models.items():\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        svm_model = pickle.load(f)\n",
    "\n",
    "    model_fn = lambda smiles: model(smiles, svm_model)\n",
    "\n",
    "    samples = exmol.sample_space(smiles, model_fn, batched=False)\n",
    "    counterfactual_explain(samples, isoform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheminf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
